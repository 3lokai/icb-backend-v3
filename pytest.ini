[tool:pytest]
# Pytest configuration for ICB Backend v3

# Test discovery
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Output options
addopts = 
    -v
    --tb=short
    --strict-markers
    --disable-warnings
    --cov=src
    --cov-report=term-missing
    --cov-report=html:htmlcov
    --cov-report=xml:coverage.xml
    --cov-fail-under=85
    --durations=10
    --maxfail=5

# Markers
markers =
    unit: Unit tests
    integration: Integration tests
    contract: Contract tests
    performance: Performance tests
    slow: Slow running tests
    database: Database tests
    rpc: RPC function tests
    parser: Parser tests
    normalizer: Normalizer tests
    validator: Validator tests
    fetcher: Fetcher tests
    llm: LLM tests
    monitoring: Monitoring tests
    security: Security tests

# Test categories
# Unit tests: Fast, isolated tests
# Integration tests: End-to-end tests with external dependencies
# Contract tests: RPC and database schema validation
# Performance tests: Speed and memory benchmarks
# Database tests: Database-specific functionality

# Coverage requirements
# - Parser modules: 90%+ coverage
# - Normalizer modules: 90%+ coverage  
# - RPC functions: 95%+ coverage
# - Integration tests: 85%+ coverage
# - Sample data tests: 100% coverage for critical paths

# Performance benchmarks
# - Unit tests: Complete execution within 2 minutes
# - Integration tests: Complete execution within 5 minutes
# - Contract tests: Complete execution within 3 minutes
# - Sample data tests: Complete execution within 10 minutes
# - Total CI pipeline: Complete execution within 15 minutes

# Test execution order
# 1. Unit tests (fastest, most isolated)
# 2. Integration tests (moderate speed, external dependencies)
# 3. Contract tests (RPC validation, database schema)
# 4. Performance tests (benchmarks, memory usage)
# 5. Sample data tests (real data validation)

# Error handling
# - Test failures: Clear error messages and stack traces
# - Coverage reports: HTML and text coverage reports
# - Quality metrics: Code complexity, maintainability scores
# - Performance reports: Memory usage, execution time metrics
# - Database reports: Schema validation, migration status

# CI Pipeline integration
# - All tests pass in CI environment
# - Database setup and teardown works correctly
# - Sample data processing works correctly
# - Coverage reports generated correctly
# - Quality metrics calculated correctly
# - Error reporting works correctly
